{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightningchart as lc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "with open('D:/Computer Aplication/WorkPlacement/Projects/shared_variable.txt', 'r') as f:\n",
    "    mylicensekey = f.read().strip()\n",
    "lc.set_license(mylicensekey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DATE_TIME  PLANT_ID       SOURCE_KEY  DC_POWER  AC_POWER  DAILY_YIELD  \\\n",
      "0 2020-05-15   4136001  4UPUqMRk7TRMgml       0.0       0.0  9425.000000   \n",
      "1 2020-05-15   4136001  81aHJ1q11NBPMrL       0.0       0.0     0.000000   \n",
      "2 2020-05-15   4136001  9kRcWv60rDACzjR       0.0       0.0  3075.333333   \n",
      "3 2020-05-15   4136001  Et9kgGMDl729KT4       0.0       0.0   269.933333   \n",
      "4 2020-05-15   4136001  IQ2d7wF4YD8zU1Q       0.0       0.0  3177.000000   \n",
      "\n",
      "    TOTAL_YIELD  \n",
      "0  2.429011e+06  \n",
      "1  1.215279e+09  \n",
      "2  2.247720e+09  \n",
      "3  1.704250e+06  \n",
      "4  1.994153e+07  \n",
      "            DATE_TIME  PLANT_ID       SOURCE_KEY  AMBIENT_TEMPERATURE  \\\n",
      "0 2020-05-15 00:00:00   4136001  iq8k7ZNt4Mwm3w0            27.004764   \n",
      "1 2020-05-15 00:15:00   4136001  iq8k7ZNt4Mwm3w0            26.880811   \n",
      "2 2020-05-15 00:30:00   4136001  iq8k7ZNt4Mwm3w0            26.682055   \n",
      "3 2020-05-15 00:45:00   4136001  iq8k7ZNt4Mwm3w0            26.500589   \n",
      "4 2020-05-15 01:00:00   4136001  iq8k7ZNt4Mwm3w0            26.596148   \n",
      "\n",
      "   MODULE_TEMPERATURE  IRRADIATION  \n",
      "0           25.060789          0.0  \n",
      "1           24.421869          0.0  \n",
      "2           24.427290          0.0  \n",
      "3           24.420678          0.0  \n",
      "4           25.088210          0.0  \n"
     ]
    }
   ],
   "source": [
    "generation_data = pd.read_csv('D:/wenprograming23/src/team6/Implementation-of-a-Solar-Power-Modelling-Application-with-LightningChart-Python/Dataset/Plant_2_Generation_Data.csv')\n",
    "weather_data = pd.read_csv('D:/wenprograming23/src/team6/Implementation-of-a-Solar-Power-Modelling-Application-with-LightningChart-Python/Dataset/Plant_2_Weather_Sensor_Data.csv')\n",
    "\n",
    "generation_data['DATE_TIME'] = pd.to_datetime(generation_data['DATE_TIME'])\n",
    "weather_data['DATE_TIME'] = pd.to_datetime(weather_data['DATE_TIME'])\n",
    "\n",
    "print(generation_data.head())\n",
    "print(weather_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DATE_TIME  PLANT_ID     SOURCE_KEY_x  DC_POWER  AC_POWER  DAILY_YIELD  \\\n",
      "0 2020-05-15   4136001  4UPUqMRk7TRMgml       0.0       0.0  9425.000000   \n",
      "1 2020-05-15   4136001  81aHJ1q11NBPMrL       0.0       0.0     0.000000   \n",
      "2 2020-05-15   4136001  9kRcWv60rDACzjR       0.0       0.0  3075.333333   \n",
      "3 2020-05-15   4136001  Et9kgGMDl729KT4       0.0       0.0   269.933333   \n",
      "4 2020-05-15   4136001  IQ2d7wF4YD8zU1Q       0.0       0.0  3177.000000   \n",
      "\n",
      "    TOTAL_YIELD     SOURCE_KEY_y  AMBIENT_TEMPERATURE  MODULE_TEMPERATURE  \\\n",
      "0  2.429011e+06  iq8k7ZNt4Mwm3w0            27.004764           25.060789   \n",
      "1  1.215279e+09  iq8k7ZNt4Mwm3w0            27.004764           25.060789   \n",
      "2  2.247720e+09  iq8k7ZNt4Mwm3w0            27.004764           25.060789   \n",
      "3  1.704250e+06  iq8k7ZNt4Mwm3w0            27.004764           25.060789   \n",
      "4  1.994153e+07  iq8k7ZNt4Mwm3w0            27.004764           25.060789   \n",
      "\n",
      "   IRRADIATION  \n",
      "0          0.0  \n",
      "1          0.0  \n",
      "2          0.0  \n",
      "3          0.0  \n",
      "4          0.0  \n"
     ]
    }
   ],
   "source": [
    "merged_data = pd.merge(generation_data, weather_data, on=['DATE_TIME', 'PLANT_ID'])\n",
    "\n",
    "print(merged_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = merged_data[['DC_POWER', 'AC_POWER', 'AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE', 'IRRADIATION']]\n",
    "\n",
    "corr_matrix = selected_features.corr()\n",
    "\n",
    "heatmap_data = corr_matrix.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:53136\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x221ac3d6b90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the heatmap chart\n",
    "chart = lc.ChartXY(\n",
    "    theme=lc.Themes.White,\n",
    "    title='Correlation Heatmap of Solar Plant Features'\n",
    ")\n",
    "\n",
    "# Create the heatmap grid series\n",
    "series = chart.add_heatmap_grid_series(\n",
    "    columns=len(heatmap_data),\n",
    "    rows=len(heatmap_data[0])\n",
    ")\n",
    "\n",
    "# Customize the heatmap\n",
    "series.hide_wireframe()\n",
    "series.set_intensity_interpolation(False)\n",
    "series.invalidate_intensity_values(heatmap_data)\n",
    "\n",
    "# Define color steps for the heatmap\n",
    "series.set_palette_colors(\n",
    "    steps=[\n",
    "        {\"value\": -1.0, \"color\": lc.Color(0, 0, 255)},  # Blue for negative correlation\n",
    "        {\"value\": 0.0, \"color\": lc.Color(255, 255, 255)},  # White for no correlation\n",
    "        {\"value\": 1.0, \"color\": lc.Color(255, 0, 0)}  # Red for positive correlation\n",
    "    ],\n",
    "    look_up_property='value',\n",
    "    percentage_values=False\n",
    ")\n",
    "\n",
    "# Customize the x and y axes\n",
    "x_axis = chart.get_default_x_axis()\n",
    "x_axis.set_title('Feature Index')\n",
    "x_axis.set_interval(0, len(selected_features.columns))\n",
    "\n",
    "y_axis = chart.get_default_y_axis()\n",
    "y_axis.set_title('Feature Index')\n",
    "y_axis.set_interval(0, len(selected_features.columns))\n",
    "\n",
    "# Open the chart\n",
    "chart.open()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = merged_data[['IRRADIATION', 'AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE']]\n",
    "target = merged_data['AC_POWER']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42),\n",
    "    \"LightGBM\": LGBMRegressor(random_state=42),\n",
    "    \"CatBoost\": CatBoostRegressor(verbose=0, random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 54158, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 241.709585\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 54158, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 241.709585\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:59612\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x221cdc691d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Aug/2024 22:42:57] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "dashboard = lc.Dashboard(\n",
    "    columns=3,\n",
    "    rows=2,\n",
    "    theme=lc.Themes.Dark\n",
    ")\n",
    "\n",
    "def add_feature_importance_to_dashboard(dashboard, model_name, importances, column_index, row_index):\n",
    "    \"\"\"\n",
    "    Add a feature importance bar chart to the dashboard.\n",
    "    \"\"\"\n",
    "    importance_df = pd.DataFrame({'Feature': features.columns, 'Importance': importances})\n",
    "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    chart = dashboard.BarChart(\n",
    "        column_index=column_index,\n",
    "        row_index=row_index,\n",
    "        row_span=1,\n",
    "        column_span=1\n",
    "    )\n",
    "    chart.set_title(f'{model_name} Feature Importances')\n",
    "    \n",
    "    bar_data = [{'category': str(row['Feature']), 'value': float(row['Importance'])} for _, row in importance_df.iterrows()]\n",
    "    chart.set_data(bar_data)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), features.columns)\n",
    "    ])\n",
    "\n",
    "for i, (model_name, model) in enumerate(models.items()):\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        importances = np.abs(model.coef_)  \n",
    "    else:\n",
    "        importances = np.zeros(len(features.columns))\n",
    "\n",
    "    add_feature_importance_to_dashboard(\n",
    "        dashboard=dashboard,\n",
    "        model_name=model_name,\n",
    "        importances=importances,\n",
    "        column_index=i % 3,\n",
    "        row_index=i // 3\n",
    "    )\n",
    "\n",
    "estimators = [\n",
    "    ('rf', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "    ('xgb', XGBRegressor(random_state=42)),\n",
    "    ('lgbm', LGBMRegressor(random_state=42)),\n",
    "    ('cat', CatBoostRegressor(verbose=0, random_state=42))\n",
    "]\n",
    "\n",
    "voting_reg = VotingRegressor(estimators=estimators)\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', voting_reg)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "ensemble_importances = np.mean([\n",
    "    pipeline.named_steps['regressor'].estimators_[i].feature_importances_\n",
    "    for i in range(len(pipeline.named_steps['regressor'].estimators_))\n",
    "], axis=0)\n",
    "\n",
    "add_feature_importance_to_dashboard(\n",
    "    dashboard=dashboard,\n",
    "    model_name='Ensemble Methods',\n",
    "    importances=ensemble_importances,\n",
    "    column_index=2,\n",
    "    row_index=1\n",
    ")\n",
    "\n",
    "dashboard.open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 54158, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 241.709585\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 54158, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 241.709585\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type float32 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 58\u001b[0m\n\u001b[0;32m     54\u001b[0m voting_reg \u001b[38;5;241m=\u001b[39m VotingRegressor(estimators\u001b[38;5;241m=\u001b[39mestimators)\n\u001b[0;32m     56\u001b[0m add_prediction_vs_actual_to_dashboard(dashboard, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnsemble Methods\u001b[39m\u001b[38;5;124m'\u001b[39m, voting_reg, column_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, row_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m \u001b[43mdashboard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Soroush\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightningchart\\charts\\__init__.py:50\u001b[0m, in \u001b[0;36mChart.open\u001b[1;34m(self, method, live, width, height)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance\u001b[38;5;241m.\u001b[39msend(i[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m], i[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommand\u001b[39m\u001b[38;5;124m'\u001b[39m], i[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnotebook\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_in_notebook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance\u001b[38;5;241m.\u001b[39mopen_in_browser()\n",
      "File \u001b[1;32mc:\\Users\\Soroush\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightningchart\\instance.py:131\u001b[0m, in \u001b[0;36mInstance.open_in_notebook\u001b[1;34m(self, width, height)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m IFrame(src\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconf\u001b[38;5;241m.\u001b[39mLOCALHOST\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconf\u001b[38;5;241m.\u001b[39mserver_port\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/?id=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, width\u001b[38;5;241m=\u001b[39mwidth, height\u001b[38;5;241m=\u001b[39mheight)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 131\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_html\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m display_html(html, notebook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, width\u001b[38;5;241m=\u001b[39mwidth, height\u001b[38;5;241m=\u001b[39mheight)\n",
      "File \u001b[1;32mc:\\Users\\Soroush\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightningchart\\instance.py:68\u001b[0m, in \u001b[0;36mcreate_html\u001b[1;34m(items)\u001b[0m\n\u001b[0;32m     66\u001b[0m     serialized_items \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m items:\n\u001b[1;32m---> 68\u001b[0m         serialized_items\u001b[38;5;241m.\u001b[39mappend(\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     69\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m<!DOCTYPE html>\u001b[39m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124m<html lang=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124m    <head>\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124m</html>\u001b[39m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m html\n",
      "File \u001b[1;32mc:\\Users\\Soroush\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# cached encoder\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n",
      "File \u001b[1;32mc:\\Users\\Soroush\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:200\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    202\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[1;32mc:\\Users\\Soroush\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:258\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    254\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[0;32m    255\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[1;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Soroush\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[0;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type float32 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "dashboard = lc.Dashboard(\n",
    "    columns=3,\n",
    "    rows=2,\n",
    "    theme=lc.Themes.Dark\n",
    ")\n",
    "\n",
    "def add_prediction_vs_actual_to_dashboard(dashboard, model_name, model, column_index, row_index):\n",
    "    \"\"\"\n",
    "    Add a plot of predicted vs actual values to the dashboard.\n",
    "    \"\"\"\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    chart = dashboard.ChartXY(column_index=column_index, row_index=row_index, column_span=1, row_span=1)\n",
    "    chart.set_title(f'{model_name} Predictions vs Actual')\n",
    "    \n",
    "    pred_series = chart.add_point_series()\n",
    "    pred_series.add(y_test.tolist(), y_pred.tolist()).set_name('Predicted vs Actual')\n",
    "    \n",
    "    line_series = chart.add_line_series()\n",
    "    min_val = min(min(y_test), min(y_pred))\n",
    "    max_val = max(max(y_test), max(y_pred))\n",
    "    line_series.add([min_val, max_val], [min_val, max_val])\n",
    "    line_series.set_name('Ideal Line')\n",
    "    \n",
    "    chart.get_default_x_axis().set_title('Actual AC Power')\n",
    "    chart.get_default_y_axis().set_title('Predicted AC Power')\n",
    "    \n",
    "    legend = chart.add_legend(horizontal=False)\n",
    "    legend.add(pred_series)\n",
    "    legend.add(line_series)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), features.columns)\n",
    "    ])\n",
    "\n",
    "for i, (model_name, model) in enumerate(models.items()):\n",
    "    add_prediction_vs_actual_to_dashboard(dashboard, model_name, model, column_index=i % 3, row_index=i // 3)\n",
    "\n",
    "estimators = [\n",
    "    ('rf', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "    ('xgb', XGBRegressor(random_state=42)),\n",
    "    ('lgbm', LGBMRegressor(random_state=42)),\n",
    "    ('cat', CatBoostRegressor(verbose=0, random_state=42))\n",
    "]\n",
    "\n",
    "voting_reg = VotingRegressor(estimators=estimators)\n",
    "\n",
    "add_prediction_vs_actual_to_dashboard(dashboard, 'Ensemble Methods', voting_reg, column_index=2, row_index=1)\n",
    "\n",
    "dashboard.open()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
